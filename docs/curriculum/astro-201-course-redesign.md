# ASTR 201: Astrophysical Modeling
## Course Redesign Proposal

**Institution:** San Diego State University
**Proposer:** Dr. Anna Rosen
**Collaborator:** Dr. Matt Anderson (CRMSE, Learning Glass creator)
**Date:** February 5, 2026
**Effective:** Fall 2026

---

## Table of Contents

1. [Executive Summary](#executive-summary)
2. [Why This Design Works: The Research](#why-this-design-works-the-research)
   - [Active Learning vs. Traditional Lecture](#1-active-learning-vs-traditional-lecture)
   - [Predict-Observe-Explain (POE)](#2-predict-observe-explain-poe)
   - [Interactive Simulations](#3-interactive-simulations-done-right)
   - [The Testing Effect](#4-the-testing-effect-retrieval-practice)
   - [Writing-to-Learn](#5-writing-to-learn)
   - [Flipped Classroom](#6-flipped-classroom-with-video-lectures)
   - [Peer Instruction](#7-peer-instruction)
   - [Expected Outcomes](#expected-outcomes-based-on-research)
3. [⚠️ Warnings: What Can Go Wrong](#️-warnings-what-can-go-wrong)
   - [Slider-Fidgeting](#1-slider-fidgeting-exploration-without-thinking)
   - [Minimal Guidance Failure](#2-minimal-guidance-fails-novices)
   - [Assessment Misalignment](#3-assessment-misalignment)
   - [Instructor Buy-In](#4-instructor-buy-in-and-training)
   - [Technology Dependencies](#5-technology-dependencies)
   - [Workload Creep](#6-workload-creep)
   - [The "Fun = Easy" Misperception](#7-the-fun--easy-misperception)
4. [Part I: Course Identity](#part-i-course-identity)
5. [Part II: Learning Glass Theoretical Foundation](#part-ii-learning-glass-theoretical-foundation)
6. [Part III: Learning Outcomes](#part-iii-learning-outcomes)
7. [Part IV: Course Structure (15 Weeks)](#part-iv-course-structure-15-weeks)
8. [Part V: Class Session Format](#part-v-class-session-format)
9. [Part VI: Assessment Design](#part-vi-assessment-design)
10. [Part VII: Synthesis Memo Specifications](#part-vii-synthesis-memo-specifications)
11. [Part VIII: What NOT to Require in 201](#part-viii-what-not-to-require-in-201)
12. [Part IX: Relationship to Other Courses](#part-ix-relationship-to-other-courses)
13. [Part X: Implementation Requirements](#part-x-implementation-requirements)
14. [Part XI: Assessment of Course Effectiveness](#part-xi-assessment-of-course-effectiveness)
15. [Part XII: Common Concerns (FAQ)](#part-xii-common-concerns-faq)
16. [Part XIII: Comparison to Current ASTR 201](#part-xiii-comparison-to-current-astr-201)
17. [Appendices](#appendix-a-sample-weekly-schedule-week-3)

---

## Executive Summary

This document proposes a redesign of ASTR 201 using the **Cosmic Playground** interactive demo ecosystem combined with **Learning Glass pre-recorded lectures** for theoretical background. The redesigned course transforms the traditional "lecture + problem sets" format into **studio astrophysics**: a model-based, inquiry-driven approach where students learn to think like astrophysicists.

**What This Is NOT:** A reduction of theory or mathematical rigor. Students still learn equations—and learn them deeply.

**What This IS:** A better way to make students *take equations seriously*. By seeing equations in action through interactive models, students develop genuine physical intuition rather than symbol-manipulation skills that evaporate after the exam.

**The Core Philosophy:** Avoid math stigma by making learning engaging, not by removing the math. Equations are central—the demos exist to make equations *meaningful*.

**Why Now:** With ASTR 101 and PHYS 195 as enforced prerequisites, students *should* arrive with basic vocabulary and physics tools. In practice, prerequisite amnesia is real—students may not remember much. The Learning Glass lectures provide just-in-time theoretical refreshers (EM spectrum, gravity, thermodynamics) so the demos can focus on *application* rather than *remediation*.

---

## Why This Design Works: The Research

This course redesign isn't based on intuition or trend-following. Every major design decision is grounded in decades of cognitive science and discipline-based education research. Here's the evidence base.

### 1. Active Learning vs. Traditional Lecture

**The Evidence:**

> Freeman et al. (2014) conducted a meta-analysis of 225 studies comparing active learning to traditional lecturing in STEM courses. Active learning **increased exam scores by 0.47 standard deviations** and **reduced failure rates by 55%** (from 33.8% to 21.8%). The effect was so large that the authors concluded: "If the experiments analyzed here had been conducted as randomized controlled trials of medical interventions, they may have been stopped for benefit."

**How ASTR 201 Uses This:**
- Class time is 80% active (demo missions, predictions, discussions)
- Mini-lectures are ≤10 minutes
- Students do physics, not watch physics

**Citation:** Freeman, S., Eddy, S. L., McDonough, M., Smith, M. K., Okoroafor, N., Jordt, H., & Wenderoth, M. P. (2014). Active learning increases student performance in science, engineering, and mathematics. *PNAS*, 111(23), 8410-8415.

---

### 2. Predict-Observe-Explain (POE)

**The Evidence:**

> White & Gunstone (1992) demonstrated that requiring students to **commit to a prediction before observing** an outcome dramatically improves learning. When predictions are wrong, students experience "productive failure" that triggers conceptual change. Without predictions, students often assimilate new information into existing (incorrect) mental models without noticing the conflict.

> Champagne, Klopfer, & Anderson (1980) showed that prediction activities in physics courses **surfaced misconceptions** that would otherwise persist undetected until exams—when it's too late to fix them.

**How ASTR 201 Uses This:**
- Every class begins with a prediction activity
- Students commit reasoning *before* seeing demo results
- Wrong predictions become learning opportunities, not embarrassments

**Citations:**
- White, R. T., & Gunstone, R. F. (1992). *Probing Understanding*. Falmer Press.
- Champagne, A. B., Klopfer, L. E., & Anderson, J. H. (1980). Factors influencing the learning of classical mechanics. *American Journal of Physics*, 48(12), 1074-1079.

---

### 3. Interactive Simulations (Done Right)

**The Evidence:**

> The PhET Interactive Simulations project at CU Boulder has conducted extensive research on what makes simulations effective. Adams et al. (2008) found that **simulations with implicit scaffolding** (where the interface guides exploration without explicit instructions) outperformed both free exploration and heavily scripted use.

> Wieman, Adams, & Perkins (2008) showed that effective simulations share key features: **immediate feedback**, **multiple linked representations**, and **productive constraints** that prevent unphysical behavior. Critically, they found that **simulations alone don't guarantee learning**—the instructional context matters enormously.

**How ASTR 201 Uses This:**
- Demos have guided missions (not free play)
- Multiple representations: sliders + plots + equations
- Model Cards explain assumptions and limits
- Failure modes are pedagogically meaningful

**Citations:**
- Adams, W. K., Reid, S., LeMaster, R., McKagan, S. B., Perkins, K. K., Dubson, M., & Wieman, C. E. (2008). A study of educational simulations Part I: Engagement and learning. *Journal of Interactive Learning Research*, 19(3), 397-419.
- Wieman, C. E., Adams, W. K., & Perkins, K. K. (2008). PhET: Simulations that enhance learning. *Science*, 322(5902), 682-683.

---

### 4. The Testing Effect (Retrieval Practice)

**The Evidence:**

> Roediger & Butler (2011) review decades of research showing that **retrieving information from memory strengthens that memory more than re-reading or re-studying**. This "testing effect" is one of the most robust findings in cognitive psychology.

> Karpicke & Blunt (2011) found that retrieval practice produced **50% more learning** than elaborative studying with concept maps—even when the final test required concept mapping.

**How ASTR 201 Uses This:**
- Weekly low-stakes retrieval quizzes
- Concept checks during class require retrieval
- Synthesis memos require explaining from memory (not copying from demos)

**Citations:**
- Roediger, H. L., & Butler, A. C. (2011). The critical role of retrieval practice in long-term retention. *Trends in Cognitive Sciences*, 15(1), 20-27.
- Karpicke, J. D., & Blunt, J. R. (2011). Retrieval practice produces more learning than elaborative studying with concept mapping. *Science*, 331(6018), 772-775.

---

### 5. Writing-to-Learn

**The Evidence:**

> Bangert-Drowns et al. (2004) meta-analyzed 48 studies of writing-to-learn interventions and found **significant positive effects on learning** (effect size = 0.26). Critically, writing worked best when it required **metacognition**—reflection on one's own thinking—rather than simple summarization.

> In physics specifically, Kalman et al. (2008) showed that "reflective writing" assignments improved conceptual understanding by forcing students to **articulate their reasoning in complete sentences**.

**How ASTR 201 Uses This:**
- Equation Maps require term-by-term explanation in prose
- Failure Analysis requires metacognitive reflection
- Three synthesis memos distributed across semester (not one final paper)

**Citations:**
- Bangert-Drowns, R. L., Hurley, M. M., & Wilkinson, B. (2004). The effects of school-based writing-to-learn interventions on academic achievement: A meta-analysis. *Review of Educational Research*, 74(1), 29-58.
- Kalman, C. S., Aulls, M. W., Rohar, S., & Godley, J. (2008). Students' perceptions of reflective writing as a tool for exploring an introductory textbook. *Journal of College Science Teaching*, 37(4), 74-81.

---

### 6. Flipped Classroom with Video Lectures

**The Evidence:**

> Bishop & Verleger (2013) reviewed 24 studies of flipped classrooms and found that **students generally preferred the flipped format** and that learning outcomes were **equal or superior** to traditional instruction. The key advantage: class time becomes available for higher-order activities.

> Chen et al. (2014) found that flipped instruction was particularly effective in STEM courses where **conceptual understanding requires active problem-solving**, not passive reception.

**How ASTR 201 Uses This:**
- Learning Glass videos deliver theory asynchronously
- Class time is protected for demo exploration and discussion
- Students can rewatch difficult concepts (videos are forever)

**Citations:**
- Bishop, J. L., & Verleger, M. A. (2013). The flipped classroom: A survey of the research. *ASEE National Conference Proceedings*, 30(9), 1-18.
- Chen, Y., Wang, Y., Kinshuk, & Chen, N. S. (2014). Is FLIP enough? Or should we use the FLIPPED model instead? *Computers & Education*, 79, 16-27.

---

### 7. Peer Instruction

**The Evidence:**

> Mazur (1997) introduced Peer Instruction in physics and demonstrated **dramatic improvements** in conceptual understanding. Students who discussed conceptual questions with peers showed normalized gains of 0.5-0.7 on the Force Concept Inventory, compared to 0.2-0.3 for traditional instruction.

> Crouch & Mazur (2001) followed up with 10 years of data showing that **peer discussion is the key mechanism**—students who discuss before answering perform better than those who answer individually, even after controlling for initial understanding.

**How ASTR 201 Uses This:**
- Concept checks use think-pair-share format
- Demo missions are done in small groups
- Peer review workshops for synthesis memos

**Citations:**
- Mazur, E. (1997). *Peer Instruction: A User's Manual*. Prentice Hall.
- Crouch, C. H., & Mazur, E. (2001). Peer instruction: Ten years of experience and results. *American Journal of Physics*, 69(9), 970-977.

---

### Expected Outcomes Based on Research

If implemented with fidelity, the research predicts:

| Outcome | Expected Effect | Research Basis |
|---------|-----------------|----------------|
| **Exam performance** | +0.4-0.5 SD improvement | Freeman et al. (2014) |
| **Failure/DFW rate** | 40-55% reduction | Freeman et al. (2014) |
| **Conceptual understanding** | Normalized gain >0.4 | Mazur (1997); Hake (1998) |
| **Long-term retention** | Significantly improved | Roediger & Butler (2011) |
| **Student satisfaction** | Generally positive | Bishop & Verleger (2013) |
| **Upper-div preparedness** | Improved (needs tracking) | Theoretical; assess in Years 2-3 |

**Important caveat:** These outcomes require **faithful implementation**. Simulations without structure, flipping without active learning, or assessments that reward memorization will fail to produce these gains.

---

## ⚠️ Warnings: What Can Go Wrong

This section names the failure modes explicitly. Every intervention has risks. Acknowledging them upfront allows mitigation.

### 1. Slider-Fidgeting (Exploration Without Thinking)

**The Risk:** Students move sliders randomly, observe pretty plots, and learn nothing. They're "busy" but not thinking.

**Research Warning:** Clark & Mayer (2016) show that unguided discovery learning consistently underperforms guided instruction. The brain doesn't automatically extract principles from experience—it needs scaffolding.

**Mitigation in ASTR 201:**
- Predictions BEFORE exploration (forces hypothesis)
- Mission sheets with specific tasks (not "explore freely")
- Explanation requirements (can't just describe—must explain why)
- Equation Maps require connecting observations to math

**Citation:** Clark, R. C., & Mayer, R. E. (2016). *E-Learning and the Science of Instruction* (4th ed.). Wiley.

---

### 2. Minimal Guidance Fails Novices

**The Risk:** Instructors assume students will "discover" physics through demos. They won't. Novices lack the schemas to make sense of complex systems without guidance.

**Research Warning:** Kirschner, Sweller, & Clark (2006) argue that "minimally guided instruction"—including pure discovery learning—is ineffective for novices because it **overloads working memory**. Experts can explore; novices need structure.

**Mitigation in ASTR 201:**
- Learning Glass lectures provide theoretical background FIRST
- Demo missions are guided, not open-ended
- Model Cards explain what students should notice
- Instructor circulates as "modeling coach," not passive observer

**Citation:** Kirschner, P. A., Sweller, J., & Clark, R. E. (2006). Why minimal guidance during instruction does not work: An analysis of the failure of constructivist, discovery, problem-based, experiential, and inquiry-based teaching. *Educational Psychologist*, 41(2), 75-86.

---

### 3. Assessment Misalignment

**The Risk:** If exams test memorization (definitions, formulas without context), students will memorize despite the demos. The hidden curriculum of "what's on the test" always wins.

**Research Warning:** Gibbs & Simpson (2005) show that assessment drives learning more than any other course feature. Misaligned assessment undermines even excellent instruction.

**Mitigation in ASTR 201:**
- No traditional exams (synthesis memos are the summative assessment)
- Equation Maps require explanation, not reproduction
- Failure Analysis can't be memorized—requires actual demo exploration
- Rubrics explicitly value reasoning over recall

**If You Must Have Exams:** Make them open-note, application-focused. Ask "Given this model output, what went wrong?" not "Write the equation for hydrostatic equilibrium."

**Citation:** Gibbs, G., & Simpson, C. (2005). Conditions under which assessment supports students' learning. *Learning and Teaching in Higher Education*, 1, 3-31.

---

### 4. Instructor Buy-In and Training

**The Risk:** An instructor who doesn't believe in active learning will sabotage the course—consciously or not. They'll expand mini-lectures to 30 minutes, skip predictions "to save time," or grade memos on correctness rather than reasoning.

**Research Warning:** Henderson et al. (2012) found that **most physics faculty who try research-based instruction abandon it within a few years**. The main reasons: lack of support, time pressure, and discomfort with the new role.

**Mitigation in ASTR 201:**
- Instructor training workshop (required for new adopters)
- Detailed facilitator guides for each session
- Peer observation and feedback in pilot year
- Explicit discussion of the instructor's changed role

**Citation:** Henderson, C., Dancy, M., & Niewiadomska-Bugaj, M. (2012). Use of research-based instructional strategies in introductory physics: Where do faculty leave the innovation-decision process? *Physical Review Special Topics - Physics Education Research*, 8(2), 020104.

---

### 5. Technology Dependencies

**The Risk:** Demos break mid-class. WiFi goes down. Students can't run demos on their devices. The course grinds to a halt.

**Mitigation in ASTR 201:**
- Browser-based demos (no installation required)
- Offline fallback mode (planned)
- Pre-recorded demo videos for every session
- Mission sheets can be completed with screenshots if needed
- IT support contact established before semester

**Contingency Plan:** If a demo is broken on class day, use the pre-recorded video walkthrough. Students can still make predictions and discuss. The mission sheet becomes "analyze this video" rather than "run the demo yourself."

---

### 6. Workload Creep

**The Risk:** Each component seems reasonable, but the total overwhelms students. They start cutting corners, surface learning returns, and evaluations tank.

**Research Warning:** Kember (2004) found that **perceived workload** is a stronger predictor of surface learning than actual hours spent. If students feel overwhelmed, they shift to survival mode.

**Mitigation in ASTR 201:**
- Explicit time budget in syllabus (3-4 hours/week outside class)
- Check-ins at Week 3 and Week 8: "Is the workload sustainable?"
- Willingness to cut content if needed (depth > breadth)
- Three equal memos (not "one big report" that balloons)

**Citation:** Kember, D. (2004). Interpreting student workload and the factors which shape students' perceptions of their workload. *Studies in Higher Education*, 29(2), 165-184.

---

### 7. The "Fun = Easy" Misperception

**The Risk:** Some students (and colleagues) will assume that "interactive demos" means "dumbed down." They'll either coast expecting easy A's or dismiss the course as unrigorous.

**Mitigation in ASTR 201:**
- Syllabus explicitly states: "This course is rigorous. The demos exist to make equations meaningful, not to replace them."
- Equation Maps are hard—you can't fake understanding
- Failure Analysis requires genuine engagement with model limits
- Grading rubric rewards depth of reasoning

**Communication Strategy:** In the first class, show students the Equation Map rubric. Say: "This is what an A looks like. Notice that it requires you to explain what each term in the equation does physically. That's harder than memorizing the equation—but it's also what makes the equation useful."

---

### Summary: The Fragility of Good Design

This course can fail in predictable ways:

| Failure Mode | Warning Sign | Response |
|--------------|--------------|----------|
| Slider-fidgeting | Mission sheets show description but no explanation | Add more "why" prompts; require predictions |
| Novice overload | Students confused even after demos | More scaffolding; check Learning Glass completion |
| Assessment misalignment | Students ask "will this be on the test?" | Reframe: the memos ARE the test |
| Instructor drift | Mini-lectures expand; demos become demonstrations | Peer observation; facilitator guide check-ins |
| Tech failure | Demo crashes; students can't access | Backup videos ready; offline mode |
| Workload overwhelm | Student complaints; surface learning visible | Reduce scope; extend deadlines; listen |
| "Easy course" perception | Students coast; colleagues skeptical | Show Equation Map examples; emphasize rigor |

**The meta-lesson:** Good pedagogy is not "set and forget." It requires ongoing attention, adjustment, and willingness to respond to what's actually happening in the classroom.

---

## Part I: Course Identity

### Catalog Description (Proposed)

> **ASTR 201: Astrophysical Modeling (3 units)**
>
> Introduction to model-based reasoning in astrophysics. Students build and analyze physical models of stars, galaxies, and the universe using interactive simulations. Emphasis on connecting observations to physics, diagnosing model failures, and articulating uncertainty. Three hours lecture/studio per week.
>
> *Prerequisites: ASTR 101 and PHYS 195 (or equivalent calculus-based mechanics)*

### What This Course IS and ISN'T

| ASTR 201 IS | ASTR 201 IS NOT |
|-------------|-----------------|
| **Equations made meaningful** through interactive exploration | Equations as abstract symbol manipulation |
| Core equations + deep physical interpretation | Derivation as the end goal (that's upper-div) |
| Theory delivered via Learning Glass + applied via demos | Theory skipped or dumbed down |
| "Understand why the equation works" | "Memorize and plug-and-chug" |
| Preparation for upper-division rigor | Replacement for upper-division depth |
| Making physics *fun* so students engage with the math | Removing the math to make it "easier" |

**The Key Distinction:** We're not reducing theory—we're *delivering it better*. Learning Glass lectures provide the theoretical foundation. Demos let students see that theory in action. Synthesis memos require students to explain the physics in their own words.

### The Pedagogical Model

```
Theory (Learning Glass) → Prediction → Demo Exploration → Equation Map → Synthesis
         ↓                    ↓              ↓                 ↓            ↓
   (Background)          (Commit)       (Test)           (Explain)    (Write)
```

Students learn equations by *using* them to predict, test, and explain—not by watching someone else derive them on a blackboard. The derivations come in upper-division courses, *after* students have intuition for what the equations mean.

---

## Part II: Learning Glass Theoretical Foundation

### The Prerequisite Amnesia Problem

ASTR 101 and PHYS 195 are prerequisites—but "took the course" ≠ "retained the material."

**The Reality:** Students arrive having:
- Forgotten most of electromagnetic spectrum details
- Lost fluency with gravitational concepts beyond F = GMm/r²
- Never deeply internalized thermodynamic reasoning
- Fuzzy understanding of light-matter interactions

**The Problem:** We can't spend precious studio time on remediation, but we also can't assume knowledge that isn't there.

**The Solution:** Learning Glass pre-recorded lectures provide just-in-time theoretical background *outside* class time, so studio sessions can focus on application and synthesis.

### What Is Learning Glass?

Learning Glass is a transparent writing surface where the instructor faces the camera while writing. Developed by Dr. Matt Anderson at SDSU's Center for Research in Mathematics and Science Education (CRMSE), it creates a more personal, engaging lecture experience than traditional screencasts.

**Why It Works:**
- Instructor maintains eye contact while explaining
- Writing appears correctly (not mirrored)
- Students see the instructor's face AND the equations
- More engaging than disembodied voice-over slides

### Learning Glass Content for ASTR 201

Each unit has 2-3 short Learning Glass videos (10-15 min each) covering theoretical background that students need but may have forgotten or never deeply learned.

#### Stellar Structure Background (Watch before Week 2)

| Video | Duration | Content | Refreshes |
|-------|----------|---------|-----------|
| **Gravity & Equilibrium** | 12 min | Newton's law of gravitation; pressure as force/area; what "equilibrium" means; why things collapse or expand | PHYS 195 |
| **Temperature & Energy** | 10 min | Kinetic theory basics; what temperature "is"; energy conservation; heat flow | PHYS 195 |
| **Light & Radiation** | 15 min | Blackbody radiation; Wien's law; Stefan-Boltzmann; what a spectrum tells us | ASTR 101 |

#### Galaxies Background (Watch before Week 7)

| Video | Duration | Content | Refreshes |
|-------|----------|---------|-----------|
| **Circular Motion & Orbits** | 12 min | Centripetal acceleration; orbital velocity; Kepler's third law; what "dynamics" means | PHYS 195 |
| **Electromagnetic Spectrum** | 10 min | From radio to gamma; what different wavelengths show us; why multi-wavelength matters | ASTR 101 |
| **Stellar Populations** | 12 min | What stars tell us about galaxies; HR diagram recap; mass-to-light ratios | ASTR 101 |

#### Cosmology Background (Watch before Week 12)

| Video | Duration | Content | Refreshes |
|-------|----------|---------|-----------|
| **The Expanding Universe** | 15 min | Hubble's discovery; what "expansion" means (not explosion); cosmological redshift | ASTR 101 |
| **Light Travel Time** | 10 min | Speed of light limit; lookback time; seeing the past; light-years as distance | ASTR 101 |
| **The Big Bang Evidence** | 12 min | CMB overview; element abundances; timeline of the universe | ASTR 101 |

### How Learning Glass Integrates with Studio Sessions

```
BEFORE CLASS (Asynchronous):
├── Watch Learning Glass video (10-15 min) → Theoretical foundation
├── Complete vocabulary check (5 min) → Confirm understanding
└── Make prediction (5 min) → Commit to reasoning

IN CLASS (Synchronous):
├── Mini-lecture (10 min) → Connect theory to today's model
├── Demo mission (35 min) → Apply theory, test predictions
├── Concept checks (15 min) → Surface misconceptions
└── Synthesis discussion (15 min) → Consolidate learning

AFTER CLASS (Asynchronous):
├── Complete mission sheet (45-60 min) → Document learning
└── Retrieval quiz (15 min) → Memory consolidation
```

### The Key Insight: Division of Labor

| Delivery Method | Purpose | When |
|-----------------|---------|------|
| **Learning Glass** | Theoretical background, prerequisites refresher, "the why" | Before class (async) |
| **Mini-lecture** | Connect theory to today's model, set up the demo | Start of class (5-10 min) |
| **Demos** | Apply theory, test predictions, build intuition | In-class (35-40 min) |
| **Synthesis Memos** | Explain physics in own words, connect equations to experiments | End of unit |

This division means:
- **Theory isn't skipped**—it's delivered more efficiently via video
- **Class time is protected** for active learning
- **Students can rewatch** difficult concepts (videos are forever)
- **Prerequisites are refreshed** without embarrassing students who forgot

---

## Part III: Learning Outcomes

### What Students "Earn" Before Upper-Division

The goal is **schema-level understanding**, not encyclopedic coverage. Students should be able to *reason* about astrophysical systems, even ones they haven't seen before.

#### Stellar Structure Outcomes

| Outcome | Assessment Evidence |
|---------|---------------------|
| Explain hydrostatic equilibrium causally (not just recite) | Can answer: "Why doesn't the Sun collapse or explode?" |
| Predict how changing M, κ, composition shifts structure | Given a parameter change, predicts direction of effect before seeing demo |
| Read a radial profile and identify what dominates where | Given an unlabeled profile, identifies gas vs radiation pressure, radiative vs convective zones |
| Articulate what polytropes do and don't capture | Can explain: "Why are real stars not polytropes?" |

#### Galaxies Outcomes

| Outcome | Assessment Evidence |
|---------|---------------------|
| Go from light → stellar mass (with uncertainty) | Correctly applies M/L ratio and discusses its limitations |
| Use rotation curves to argue for dark matter | Can explain: "What would the rotation curve look like without dark matter?" |
| Tell a coherent story connecting gas, SF, and regulation | Can explain feedback loop: gas → stars → feedback → regulated growth |
| Understand mass inference from dynamics | Can explain difference between luminous and dynamical mass |

#### Cosmology Outcomes

| Outcome | Assessment Evidence |
|---------|---------------------|
| Use redshift and distance measures correctly | Correctly chooses $D_A$, $D_L$, or $D_C$ for a given problem |
| Explain the $D_A$ turnover ("cosmic optical illusion") | Can explain why distant objects can appear *larger* |
| Explain BAO as a frozen acoustic ruler | Can explain: "Why is the BAO scale a standard ruler?" |
| Understand degeneracies and multi-probe inference | Can explain why SN + BAO + CMB together constrain better than any alone |

#### Cross-Cutting Outcomes

| Outcome | Assessment Evidence |
|---------|---------------------|
| Distinguish "what the model computes" from "what's real" | Every capstone includes honest limitations section |
| Make predictions before seeing results | Weekly prediction activities with reasoning |
| Diagnose model failures | Failure analysis required in every capstone |
| Communicate scientific reasoning | Capstone reports demonstrate clear scientific writing |

---

## Part IV: Course Structure (15 Weeks)

### The "Sweet Spot" Design

Rigorous but not soul-crushing. Keep all three suites, but vary the depth:

| Unit | Duration | Depth | Why |
|------|----------|-------|-----|
| **Modeling Bootcamp** | 1 week | Foundation | Establish the course's way of thinking |
| **Stellar Structure** | 5 weeks | Deep | This is the conceptual core of astrophysics |
| **Galaxies** | 5 weeks | Medium | Inference from observables + dark matter logic |
| **Cosmology** | 3 weeks | Focused | Expansion/distances/BAO + basic inference |
| **Synthesis** | 1 week | Integration | Cross-suite connections + presentations |

### 15-Week Calendar

| Week | Unit | Topics | Demos | Deliverables |
|------|------|--------|-------|--------------|
| **1** | Bootcamp | Units, scaling, log thinking, observable→model→inference | — | Mini-cap: Explain a plot |
| **2** | Stellar | What holds a star up? EOS + HSE | 1-2 | Mission Sheet 1 |
| **3** | Stellar | Timescales + Polytropes | 3-4 | Mission Sheet 2 |
| **4** | Stellar | Energy generation + Opacity | 5-6 | Mission Sheet 3 |
| **5** | Stellar | Transport + Capstone demo | 7-8 | Mission Sheet 4 |
| **6** | Stellar | **Synthesis Memo 1 workshop + peer review** | — | **Synthesis Memo 1** |
| **7** | Galaxies | Light and mass: Anatomy + Photometry | 1-2 | Mission Sheet 5 |
| **8** | Galaxies | Mass from motion: Rotation + Dispersion | 3-4 | Mission Sheet 6 |
| **9** | Galaxies | The baryon cycle: Gas/SF + Feedback | 5-6 | Mission Sheet 7 |
| **10** | Galaxies | Interactions + Scaling relations | 7-8 | Mission Sheet 8 |
| **11** | Galaxies | **Synthesis Memo 2 workshop + peer review** | — | **Synthesis Memo 2** |
| **12** | Cosmology | Expansion + Redshift + Distances | 1-3 | Mission Sheet 9 |
| **13** | Cosmology | Friedmann + Thermal + Recombination/BAO | 4-7 | Mission Sheet 10 |
| **14** | Cosmology | Growth + Probes Lab inference | 8-9 | **Synthesis Memo 3** |
| **15** | Synthesis | Cross-suite connections + presentations | — | **Final Synthesis** |

### Capstone Structure: Three Equal Synthesis Memos

**The Philosophy:** Every suite deserves equal synthesis. Rather than frontloading writing effort, students produce three comparable deliverables—each requiring them to explain physics, interpret equations, and connect models to observations.

**The Format:** ~4 pages of text + figures (figures separate, not counting toward page limit)

| Deliverable | Focus | Length | When |
|-------------|-------|--------|------|
| **Synthesis Memo 1** (Stellar) | Build-a-Star | ~4 pages + figures | Week 6 |
| **Synthesis Memo 2** (Galaxies) | Galaxy Autopsy | ~4 pages + figures | Week 11 |
| **Synthesis Memo 3** (Cosmology) | Fit the Universe | ~4 pages + figures | Week 14 |
| **Final Synthesis** | Cross-Suite Connections | Concept Map + 2-page reflection | Week 15 |

**Why Equal Memos:**
- Each suite builds different physics reasoning skills—all deserve synthesis
- Avoids "big report burnout" that leads to superficial final work
- Students practice scientific writing three times, not once
- Figures saved from demos become central evidence (not afterthought)

---

## Part V: Class Session Format

### Studio Astrophysics (75-minute session)

| Time | Activity | Purpose |
|------|----------|---------|
| 0-10 min | **Mini-lecture** | Frame the physics question; set up the model |
| 10-15 min | **Prediction reveal** | Students share predictions; surface misconceptions |
| 15-50 min | **Demo mission** (small groups) | Structured exploration with worksheet |
| 50-65 min | **Concept checks** | Peer instruction; clicker questions |
| 65-75 min | **Synthesis discussion** | "What did we learn? What questions remain?" |

### The Instructor's New Role

You become a **modeling coach**, not a content deliverer:

- "Show me your run—tell me what assumption caused that behavior"
- "Your prediction was wrong—what did you learn?"
- "The model broke—is that a bug or a feature?"

### What Changes from Traditional Format

| Traditional | Studio Astrophysics |
|-------------|---------------------|
| Lecture dominates class time | Lecture is 10-15 minutes max |
| Derivations on blackboard | "Here's the model; predict, test, explain; *then* we discuss the math" |
| Homework: "Solve for X" | Homework: "Interpret your run; explain the residuals" |
| Labs are separate | Demos ARE the lab bench (integrated) |
| Misconceptions found on exam | Misconceptions surfaced in predictions (fixable) |

---

## Part VI: Assessment Design

### Grade Weights

| Component | Weight | Frequency | Purpose |
|-----------|--------|-----------|---------|
| **Prediction Activities** | 5% | Before each class | Commit to predictions; surface misconceptions |
| **Mission Sheets** | 20% | Weekly | Guided exploration; retrieval practice |
| **Retrieval Quizzes** | 10% | Weekly (low-stakes) | Testing effect; memory consolidation |
| **Synthesis Memos** | 36% | 3 total | Three equal memos @ 12% each |
| **Final Synthesis** | 14% | End of semester | Concept map + cross-suite connections |
| **Participation** | 15% | Ongoing | Peer discussion; concept checks; workshop contribution |

### Time Budget (Be Honest with Students)

| Activity | Weekly Time | Notes |
|----------|-------------|-------|
| Learning Glass videos | 20-30 min | Theoretical background (not every week) |
| Pre-class prep | 20-30 min | Reading + vocabulary check + prediction |
| In-class | 75-150 min | 1-2 sessions per week |
| Mission sheet completion | 45-60 min | After class |
| Retrieval quiz | 15-20 min | Low-stakes |
| **Total weekly** | **~3-4 hours outside class** | Appropriate for 3-unit course |

**Synthesis Memo weeks:** Additional 8-10 hours per memo (three times per semester).

**Learning Glass Note:** Videos are front-loaded in each unit. Students watch ~1-2 hours of video before each unit begins, not every week. This makes the time budget sustainable.

### What "Mastery" Means in 201

**Not this:** Derive the four stellar structure equations in full generality.

**This:** Explain what each equation *does*, predict what happens when you change a parameter, and diagnose why a model failed.

**Not this:** Run full MCMC cosmology inference.

**This:** Understand why χ² changes when you adjust parameters, and explain why combining probes breaks degeneracies.

---

## Part VII: Synthesis Memo Specifications

### The Four Artifacts (Required in Every Synthesis Memo)

Every synthesis memo must include these four components:

| Artifact | What It Is | Why It Matters |
|----------|------------|----------------|
| **1. Signature Figure** | The ONE plot that tells the story (saved from demo) | Forces prioritization; evidence-based argument |
| **2. Equation Map** | 2-3 core equations with term-by-term physical meaning | Connects math to physics; proves understanding |
| **3. Failure Analysis** | "I broke the model by pushing X; here's what that teaches" | Demonstrates understanding of limits |
| **4. Inference Statement** | "Given these observables, what can/can't we conclude?" | Scientific bottom line |

**Figures:** Students save figures directly from demos (screenshot or export). Figures do NOT count toward the ~4 page limit. Expect 3-5 figures per memo.

### Synthesis Memo 1: Build-a-Star (~4 pages + figures)

**Student Goal:** Pick M and composition, choose physics toggles, produce a star that lands plausibly on the HR diagram.

**Required Sections:**

| Section | Content | Length |
|---------|---------|--------|
| **Introduction** | What is hydrostatic equilibrium? Why doesn't the Sun collapse or explode? | ~0.5 page |
| **My Star** | Mass, composition, physics choices; final HR diagram position | ~0.5 page |
| **Equation Map** | At least 3 equations with term-by-term physical interpretation | ~1 page |
| **Parameter Exploration** | What changed when you varied M, κ, or composition? | ~0.5 page |
| **Failure Analysis** | What broke when you pushed too hard? What does this teach? | ~0.5 page |
| **Inference Statement** | "My star is [type] because..." with explicit physics reasoning | ~0.5 page |

**Key Equations to Map:**
- Hydrostatic equilibrium: $\frac{dP}{dr} = -\frac{Gm(r)\rho}{r^2}$
- Mass continuity: $\frac{dm}{dr} = 4\pi r^2 \rho$
- Luminosity-mass relation (concept): $L \propto M^{\alpha}$

### Synthesis Memo 2: Galaxy Autopsy (~4 pages + figures)

**Student Goal:** Given observables (light, rotation curve, gas), infer the dark matter content and tell a coherent story.

**Required Sections:**

| Section | Content | Length |
|---------|---------|--------|
| **Introduction** | Why do we believe dark matter exists? | ~0.5 page |
| **The Patient** | Observable properties: luminosity, colors, gas mass, rotation | ~0.5 page |
| **The Autopsy** | Mass from light vs. mass from dynamics; DM fraction | ~1 page |
| **Equation Map** | At least 3 equations with term-by-term physical interpretation | ~1 page |
| **Failure Analysis** | What if you remove DM? Turn off feedback? | ~0.5 page |
| **Inference Statement** | "This galaxy has __% dark matter because..." | ~0.5 page |

**Key Equations to Map:**
- Circular velocity: $v_c(r) = \sqrt{\frac{GM(<r)}{r}}$
- Mass-to-light ratio: $M_* = (M/L) \times L$
- NFW profile or isothermal halo (concept)

### Synthesis Memo 3: Fit the Universe (~4 pages + figures)

**Student Goal:** Use 2+ probes to constrain cosmological parameters; explain degeneracies.

**Required Sections:**

| Section | Content | Length |
|---------|---------|--------|
| **Introduction** | What are we measuring? Why is multi-probe inference needed? | ~0.5 page |
| **Probes Used** | What does each probe measure? What does it constrain? | ~1 page |
| **Results** | Best-fit parameters compared to reference cosmology | ~0.5 page |
| **Equation Map** | At least 3 equations with term-by-term physical interpretation | ~1 page |
| **Degeneracy Explanation** | Why do probes have different orientations in parameter space? | ~0.5 page |
| **Inference Statement** | "The universe is [flat/accelerating/DE-dominated] because..." | ~0.5 page |

**Key Equations to Map:**
- Friedmann equation: $H^2 = \frac{8\pi G}{3}\rho - \frac{kc^2}{a^2} + \frac{\Lambda c^2}{3}$
- Luminosity distance: $D_L = (1+z) \cdot D_C$
- BAO scale or sound horizon (concept)

### Final Synthesis (Concept Map + Reflection)

**Student Goal:** Connect the three suites; articulate what astrophysics *is* as a discipline.

**Requirements (~2 pages + concept map):**

| Component | Content |
|-----------|---------|
| **Concept Map** | Visual diagram showing at least 5 connections across suites (equilibrium, inference, timescales, mass measurement, etc.) |
| **Reflection** | Answer: "How does inference work differently in stars vs galaxies vs cosmology? What's the same?" (~1 page) |
| **Equations Across Suites** | Identify one equation type that appears in all three contexts (e.g., equilibrium, mass measurement, distance) (~0.5 page) |
| **What I Learned** | Personal reflection on how your thinking about astrophysics changed (~0.5 page) |

**The Cross-Suite Connections:**
- **Equilibrium:** Stellar HSE → Virial theorem in galaxies → Cosmic energy budget
- **Mass Measurement:** Interior mass from rotation → DM from dynamics → $\Omega_m$ from probes
- **Timescales:** Nuclear/KH → Dynamical/crossing → Hubble/lookback
- **Inference:** Model → Observable → Constraint (the core of astrophysics)

---

## Part VIII: What NOT to Require in 201

These are explicitly **out of scope** for 201. They belong in upper-division courses:

| Topic | Why Not 201 | Where It Belongs |
|-------|-------------|------------------|
| Full derivation of stellar structure equations | Requires mathematical physics depth | ASTR 301: Stellar Interiors |
| Jeans analysis and distribution functions | Requires statistical mechanics | ASTR 302: Galactic Dynamics |
| Boltzmann hierarchy / CMB $C_\ell$ | Requires graduate-level cosmology | ASTR 303: Cosmology or grad course |
| Full MCMC implementation | Requires computational methods | ASTR 310: Computational Astrophysics |
| N-body simulation implementation | Requires numerical methods | ASTR 310 |
| Lane-Emden derivation from first principles | 201 uses it; 301 derives it | ASTR 301 |

**The trade-off is explicit:** 201 builds intuition and reasoning; upper-div courses add rigor and depth.

---

## Part IX: Relationship to Other Courses

### Prerequisites

| Course | What Students Bring | How 201 Uses It |
|--------|---------------------|-----------------|
| **ASTR 101** | HR diagram, galaxy types, Big Bang basics | Demos build on these concepts; no re-teaching |
| **PHYS 195** | F=ma, energy conservation, basic thermo | Equilibrium, timescales, energy generation |

### Preparation for Upper-Division

| Course | What 201 Provides |
|--------|-------------------|
| **ASTR 301: Stellar Interiors** | Intuition for HSE, transport, stability; students ready for derivations |
| **ASTR 302: Galaxies** | Dark matter reasoning, rotation curves, scaling relations; ready for dynamics |
| **ASTR 303: Cosmology** | Distance measures, BAO, inference; ready for perturbation theory |
| **ASTR 310: Computational** | Exposure to models and parameter exploration; ready for implementation |

### The Two-Semester Alternative

For programs wanting a slower pace:

| Semester | Course | Content |
|----------|--------|---------|
| Fall | ASTR 201A | Stellar + Galaxies (deeper; two full reports) |
| Spring | ASTR 201B | Cosmology + Advanced topics + Research project |

---

## Part X: Implementation Requirements

### Technical Requirements

| Requirement | Status |
|-------------|--------|
| Browser-based demos (no installation) | ✓ Demos are web-native |
| Works on student laptops | ✓ Chrome/Firefox/Safari/Edge |
| LMS integration | Planned (Canvas embed via iframe) |
| Demo autologging for grading | Planned (JSON export) |

### Instructor Preparation

| Activity | Time | When |
|----------|------|------|
| Review all demos | ~8 hours | Before semester |
| Customize mission sheets | ~4 hours | Before semester |
| Prepare concept check questions | ~2 hours/week | Ongoing |
| Grade mission sheets | ~2 hours/week | Ongoing |
| Grade capstones | ~6 hours each | 3× per semester |

### Classroom Requirements

- Projector/screen for demo demonstrations
- Students bring laptops OR computer lab access
- Small-group seating preferred (tables, not lecture hall)

---

## Part XI: Assessment of Course Effectiveness

### Direct Measures

| Measure | Method | Target |
|---------|--------|--------|
| Conceptual understanding | Pre/post concept inventory | >0.3 normalized gain |
| Model-based reasoning | Capstone rubrics | >70% at "proficient" or above |
| Prediction accuracy improvement | Track prediction success rate over semester | Improvement visible |

### Indirect Measures

| Measure | Method | Target |
|---------|--------|--------|
| Student satisfaction | End-of-course evaluation | >4.0/5.0 |
| Upper-div performance | Track 201 students in 301/302/303 | Faculty report improved preparation |
| Persistence | Track astronomy major retention | Maintained or improved |

### Research Questions (for IUSE assessment)

1. Do students develop transferable model-based reasoning skills?
2. Does the demo ecosystem reduce misconception persistence compared to traditional instruction?
3. Do students from 201 perform better in upper-division courses?

---

## Part XII: Common Concerns (FAQ)

### "Is this dumbing down the course?"

**No—emphatically no.** Students still learn the same equations. The difference is *how* they learn them.

Traditional approach: Derive equation on board → students copy it → solve problem set → forget it after the exam.

This approach: See equation in action → predict what happens when you change a term → test the prediction → explain in your own words what each term does → remember it because you *understand* it.

The Equation Maps in every synthesis memo require students to explain physics term-by-term. That's *harder* than plug-and-chug, not easier. And the Learning Glass lectures deliver the same theoretical background—students just watch them outside class so we can use class time for active learning.

### "Are you removing the math?"

**Absolutely not.** Every synthesis memo requires equation maps where students explain the physics of each term. Students can't fake this—you either understand what $\frac{dP}{dr}$ means physically, or you don't.

The goal is avoiding *math stigma*—the feeling that equations are scary symbols rather than descriptions of physical reality. When students see an equation "work" in a demo, they take it seriously. When they just memorize it for an exam, it evaporates.

**The math is central. The demos exist to make the math meaningful.**

### "What about students who want more rigor?"

Offer optional "Advanced Track" activities:
- Full derivations (for those interested)
- Extended exploration in Advanced mode
- Connection to research literature

These don't count for extra credit—they're for students who want to go deeper.

### "What if the demos break?"

- All demos have "graceful degradation" (show error messages, not crashes)
- Backup: pre-recorded demo videos for each session
- Mission sheets can be completed with screenshots from videos if needed

### "How is this different from just playing with simulations?"

The key difference is **structure**:
- Predictions before exploration (commit to reasoning)
- Guided missions (not free play)
- Explanation requirements (not just observation)
- Failure analysis (understanding limits)

Without structure, interactive simulations produce "slider-fidgeting." With structure, they produce learning.

### "Will students complain about the workload?"

Calibration matters. The course is designed for ~3-4 hours/week outside class (appropriate for 3 units). Be transparent about time expectations from Day 1.

---

## Part XIII: Comparison to Current ASTR 201

| Aspect | Current 201 | Redesigned 201 |
|--------|-------------|----------------|
| **Format** | Lecture (3 hrs/wk) + problem sets | Studio (mixed lecture/activity) + missions |
| **Content delivery** | Instructor presents; students take notes | Demos present; students explore and explain |
| **Assessment** | Midterm + Final + Problem sets | Capstones + Missions + Synthesis |
| **Lab component** | Separate (if any) | Integrated (demos ARE the lab) |
| **Prerequisites** | Often not enforced | ASTR 101 + PHYS 195 required |
| **Upper-div prep** | Variable | Explicit schema-building for 301/302/303 |

---

## Appendix A: Sample Weekly Schedule (Week 3)

**Unit:** Stellar Structure
**Topic:** Timescales and Polytropes (Demos 3-4)

### Before Unit (Once, before Week 2)

**Learning Glass Videos:** (Watch once at unit start, ~35 min total)
- "Gravity & Equilibrium" (12 min)
- "Temperature & Energy" (10 min)
- "Light & Radiation" (15 min)

These videos refresh prerequisite material and set up the theoretical context for the entire stellar unit. Students can rewatch as needed throughout the unit.

### Before Class (Asynchronous, 25-35 min)

**Reading:** "Stellar Timescales" primer (2 pages)

**Prediction Activity:**
> A 10 M☉ star and a 1 M☉ star both start with the same central temperature. Which one exhausts its hydrogen fuel first? Why?

**Vocabulary Check:** (5 questions, auto-graded)
- Kelvin-Helmholtz timescale
- Nuclear timescale
- Polytrope
- Lane-Emden equation
- Polytropic index

### In-Class Session (75 min)

**Mini-lecture (10 min):**
> "Yesterday's prediction: Why do massive stars live shorter lives? Let's see why L scales faster than M..."

**Demo Mission (35 min):**
- Task 1: Compare τ_KH and τ_nuc for 1 M☉ vs 10 M☉
- Task 2: Explore polytropes with n = 1.5, 3, 4.5
- Task 3: Find the "most centrally concentrated" polytrope
- Task 4: What happens at n ≥ 5?

**Concept Checks (15 min):**
1. "If we discovered a star with τ_nuc < τ_KH, what would that tell us?"
2. "Does increasing n make a polytrope more or less centrally concentrated?"
3. "Why can't n = 5 represent a real star?"

**Synthesis Discussion (15 min):**
> "What did polytropes teach us about stellar structure that we couldn't learn from just the equations?"

### After Class (Asynchronous, 45-60 min)

**Complete Mission Sheet 2:**
- Record observations from Tasks 1-4
- Answer concept check questions
- Reflection: "What surprised you?"

**Retrieval Quiz (15 min):**
- 5 multiple-choice on timescales and polytropes
- 2 short-answer: "Explain in one sentence..."

---

## Appendix B: Grading Rubric for Synthesis Memos

| Criterion | Excellent (A) | Good (B) | Adequate (C) | Needs Work | Points |
|-----------|---------------|----------|--------------|------------|--------|
| **Signature Figure** | Clear, well-labeled, tells the story; appropriate figure choice for the argument | Good figure with minor issues | Figure present but unclear or poorly chosen | Missing or uninterpretable | /15 |
| **Equation Map** | 3+ equations with complete term-by-term physical explanation; clear "what each term does" | Good explanations with minor gaps | Equations present but limited physical interpretation | Missing or superficial | /30 |
| **Failure Analysis** | Thoughtful exploration of model limits; demonstrates genuine understanding of assumptions | Good analysis with minor gaps | Acknowledges failure but limited explanation | Missing or trivial | /15 |
| **Inference Statement** | Clear, honest, properly hedged; distinguishes what can/can't be concluded | Good statement with minor issues | Present but vague or overconfident | Missing or incorrect | /15 |
| **Physics Understanding** | Correctly explains underlying physics; connects equations to observations | Minor errors or gaps | Some correct reasoning but also misconceptions | Major misconceptions | /15 |
| **Writing Quality** | Clear, well-organized, scientific style; ~4 pages appropriate | Minor issues | Readable but disorganized or wrong length | Difficult to follow | /10 |

**Total: /100**

**Note:** Equation Map is worth 30% of the memo grade—this is intentional. Understanding what equations mean physically is the core skill we're developing.

---

## Appendix C: Transition Plan

### Year 1 (Pilot)

- Instructor teaches one section with new format
- Collect assessment data (pre/post concept inventory, capstone rubrics)
- Gather student feedback
- Refine mission sheets and pacing

### Year 2 (Expansion)

- All ASTR 201 sections use new format
- Train additional instructors
- Publish assessment results
- Refine based on Year 1 data

### Year 3 (Sustainability)

- Course fully integrated into curriculum
- Materials available to other institutions
- Assess long-term impact on upper-division performance

---

## Appendix D: Resource Requirements

### One-Time Costs

| Item | Cost | Notes |
|------|------|-------|
| Cosmic Playground license | $0 | Open-source (NSF IUSE funded) |
| Instructor training workshop | ~$500 | Optional summer workshop |
| Classroom technology upgrades | TBD | May need improved projector/WiFi |

### Ongoing Costs

| Item | Annual Cost | Notes |
|------|-------------|-------|
| Hosting/maintenance | $0 | NSF-funded infrastructure |
| TA support | Existing | No additional TA needed |
| Instructor time | Existing | Comparable to current prep |

---

*Course Redesign Proposal for ASTR 201: Astrophysical Modeling*
*Prepared for Department Curriculum Committee Review*
*San Diego State University*
